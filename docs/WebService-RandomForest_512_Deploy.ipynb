{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import pickle, json, requests, base64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Model Deployment Use Case\n",
    "\n",
    "In this case, we will build a very large ensemble model (here, Random Foreast with 512 trees) on a digits dataset  (not very original !!!) and generate a SQL code for deployment using the web service. \n",
    "\n",
    "We then execute the SQL code on a local database (postgresql) and compare the SQL execution result with scikit-learn predict/predict_proba/.predict_log_proba result. \n",
    "\n",
    "Both results are stored in pandas dataframes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a scikit-learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "n_classes = len(digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=30, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=512, n_jobs=1,\n",
       "            oob_score=False, random_state=1960, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=512, max_depth=7, min_samples_leaf=30, random_state = 1960)\n",
    "clf.fit(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate SQL Code from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_ws_sql_gen(pickle_data):\n",
    "    WS_URL=\"https://sklearn2sql.herokuapp.com/model\"\n",
    "    WS_URL=\"http://localhost:1888/model\"\n",
    "    b64_data = base64.b64encode(pickle_data).decode('utf-8')\n",
    "    data={\"Name\":\"model1\", \"PickleData\":b64_data , \"SQLDialect\":\"postgresql\"}\n",
    "    r = requests.post(WS_URL, json=data)\n",
    "    #print(r.__dict__)\n",
    "    content = r.json()\n",
    "    # print(content)\n",
    "    lSQL = content[\"model\"][\"SQLGenrationResult\"][0][\"SQL\"]\n",
    "    return lSQL;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH \"RF_0\" AS \n",
      "(WITH \"DT_node_lookup\" AS \n",
      "(SELECT \"ADS\".\"KEY\" AS \"KEY\", CASE WHEN (\"ADS\".\"Feature_43\" <= 2.5) THEN CASE WHEN (\"ADS\".\"Feature_26\" <= 3.5) THEN CASE WHEN (\"ADS\".\"Feature_19\" <= 6.5) THEN CASE WHEN (\"ADS\".\"Feature_28\" <= 15.5) THEN 4 ELSE 5 END ELSE 6 END ELSE CASE WHEN (\"ADS\".\"Feature_22\" <= 0.5) THEN CASE WHEN (\"ADS\".\"Feature_54\" <= 2.5) THEN CASE WHEN (\"ADS\".\"Feature_36\" <= 7.5) THEN 10 ELSE 11 END ELSE CASE WHEN (\"ADS\".\"Feature_33\" <= 0.5) THEN 13 ELSE 14 END END ELSE CASE WHEN (\"ADS\".\"Feature_34\" <= 7.5) THEN CASE WHEN (\"ADS\".\"Feature_44\" <= 1.5) THEN 17 ELSE 18 END ELSE CASE WHEN (\"ADS\".\"Feature_35\" <= 2.5) THEN CASE WHEN (\"ADS\".\"Feature_37\" <= 8.5) THEN 21 ELSE 22 END ELSE 23 END END END END ELSE CASE WHEN (\"ADS\".\"Feature_54\" <= 1.5) THEN CASE WHEN (\"ADS\".\"Feature_38\" <= 0.5) THEN CASE WHEN (\"ADS\".\"Feature_20\" <= 13.5) THEN CASE WHEN (\"ADS\".\"Feature_61\" <= 0.5) THEN CASE WHEN (\"ADS\".\"Feature_20\" <= 0.5) THEN 29 ELSE 30 END ELSE 31 END ELSE CASE WHEN (\"ADS\".\"Feature_35\" <= 15.5) THEN 33 ELSE CASE WHEN (\"ADS\".\"Feature_50\" <= 9.5) THEN 35 ELSE 36 END END END ELSE CASE WHEN (\"ADS\".\"Feature_53\" <= 0.5) THEN CASE WHEN (\"ADS\".\"Feature_26\" <= 12.5) THEN 39 ELSE 40 END ELSE CASE WHEN (\"ADS\".\"Feature_21\" <= 6.5) THEN 42 ELSE 43 END END END ELSE CASE WHEN (\"ADS\".\"Feature_26\" <= 7.5) THEN CASE WHEN (\"ADS\".\"Feature_9\" <= 2.5) THEN 46 ELSE CASE WHEN (\"ADS\".\"Feature_44\" <= 6.5) THEN 48 ELSE 49 END END ELSE CASE WHEN (\"ADS\".\"Feature_53\" <= 12.5) THEN CASE WHEN (\"ADS\".\"Feature_54\" <= 12.5) THEN 52 ELSE 53 END ELSE CASE WHEN (\"ADS\".\"Feature_62\" <= 1.5) THEN 55 ELSE 56 END END END END END AS node_id_2 \n",
      "FROM \"INPUT_DATA\" AS \"ADS\"), \n",
      "\"DT_node_data\" AS \n",
      "(SELECT \"Values\".nid AS nid, CAST(\"Values\".\"P_0.0\" AS FLOAT) AS \"P_0.0\", CAST(\"Values\".\"P_1.0\" AS FLOAT) AS \"P_1.0\", CAST(\"Values\".\"P_2.0\" AS FLOAT) AS \"P_2.0\", CAST(\"Values\".\"P_3.0\" AS FLOAT) AS \"P_3.0\", CAST(\"Values\".\"P_4.0\" AS FLOAT) AS \"P_4.0\", CAST(\"Values\".\"P_5.0\" AS FLOAT) AS \"P_5.0\", CAST(\"Values\".\"P_6.0\" AS F\n"
     ]
    }
   ],
   "source": [
    "pickle_data = pickle.dumps(clf)\n",
    "lSQL = test_ws_sql_gen(pickle_data)\n",
    "print(lSQL[0:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the SQL Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset in a database table\n",
    "\n",
    "engine = sa.create_engine('postgresql://db:db@localhost/db?port=5432' , echo=False)\n",
    "conn = engine.connect()\n",
    "\n",
    "lTable = pd.DataFrame(digits.data);\n",
    "lTable.columns = ['Feature_' + str(c) for c in range(digits.data.shape[1])]\n",
    "lTable['KEY'] = range(lTable.shape[0])\n",
    "lTable.to_sql(\"INPUT_DATA\" , conn,   if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_output = pd.read_sql(lSQL , conn);\n",
    "sql_output = sql_output.sort_values(by='KEY').reset_index(drop=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql_output.sample(12, random_state=1960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_output.Decision.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_outputs = pd.DataFrame()\n",
    "skl_output_key = pd.DataFrame(list(range(X.shape[0])), columns=['KEY']);\n",
    "skl_output_score = pd.DataFrame(columns=['Score_' + str(c) for c in range(n_classes)]);\n",
    "skl_output_proba = pd.DataFrame(clf.predict_proba(X), columns=['Proba_' + str(c) for c in range(n_classes)])\n",
    "skl_output_log_proba = pd.DataFrame(clf.predict_log_proba(X), columns=['LogProba_' + str(c) for c in range(n_classes)])\n",
    "skl_output_decision = pd.DataFrame(clf.predict(X), columns=['Decision'])\n",
    "skl_output = pd.concat([skl_output_key, skl_output_score, skl_output_proba, skl_output_log_proba, skl_output_decision] , axis=1)\n",
    "skl_output.sample(12, random_state=1960)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the SQL and Scikit-learn Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_skl_join = skl_output.join(sql_output , how='left', on='KEY', lsuffix='_skl', rsuffix='_sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_skl_join.sample(12, random_state=1960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (sql_skl_join.Decision_sql != sql_skl_join.Decision_skl)\n",
    "sql_skl_join[condition]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
